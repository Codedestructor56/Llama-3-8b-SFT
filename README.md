# Llama-3-8b-SFT
Fine tuning Llama-3-8b using SFT. Unfortunately, the trainer does not allow 8 bit cpu offloading while training, so my 4gb vram is prolly not enough. Try training it in colab.


4-bit quantized model(K-means) here: https://huggingface.co/EterG/Llama-3-8b-quantized-Q4_K_M
